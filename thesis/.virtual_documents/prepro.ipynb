import pandas as pd


df = pd.read_csv("dataset.csv")


df.head()


df.shape


drop_cols = df.loc[:, "CVA_tenderness":"chief_complaint"].columns


df = df.drop(columns=drop_cols)


drop_cols1 = df.loc[:, "arrival":"VITAMINS"].columns


df = df.drop(columns=drop_cols1)


columns_to_drop = ['lang', 'employStatus', 'insurance_status', 'disposition', 'dispo', 'UTI_diag', 'split', 'alt_diag', 'maritalStatus', 'race']
df = df.drop(columns=columns_to_drop)


print(list(df.columns))


df.to_csv("output_file.csv", index=False)


df.shape


print(df.head())


# Filter out rows that have 'not_reported' in any column
filtered_updated_df = df[~df.isin(['not_reported']).any(axis=1)]


# Get the number of available records for each UCX_abnormal category after filtering
yes_count_updated = filtered_updated_df[filtered_updated_df['UCX_abnormal'] == 'yes'].shape[0]
no_count_updated = filtered_updated_df[filtered_updated_df['UCX_abnormal'] == 'no'].shape[0]


# Determine the number of records we can select (up to 2500 for each)
target_count_updated = min(2500, yes_count_updated, no_count_updated)


# Sample the balanced dataset
balanced_yes_updated = filtered_updated_df[filtered_updated_df['UCX_abnormal'] == 'yes'].sample(n=target_count_updated, random_state=42)
balanced_no_updated = filtered_updated_df[filtered_updated_df['UCX_abnormal'] == 'no'].sample(n=target_count_updated, random_state=42)


# Combine the balanced dataset
balanced_updated_df = pd.concat([balanced_yes_updated, balanced_no_updated]).reset_index(drop=True)
balanced_updated_df


# Loop through each column and print its unique values
for column in balanced_updated_df.columns:
    unique_values = balanced_updated_df[column].unique()
    print(f"Column '{column}':")
    print(unique_values)
    print("\n" + "-"*50 + "\n")


# Copy the DataFrame to avoid modifying the original
encoded_df = balanced_updated_df.copy()


# Binary Encoding for binary columns
binary_columns = {
    'UCX_abnormal': {'yes': 1, 'no': 0},
    'abxUTI': {'yes': 1, 'no': 0},
    'ua_urobili': {'positive': 1, 'negative': 0},
}

for col, mapping in binary_columns.items():
    encoded_df[col] = encoded_df[col].map(mapping)

# Ordinal Encoding for columns with natural order
ordinal_mappings = {
    'ua_bacteria': ['none', 'few', 'moderate', 'marked', 'many'],
    'ua_bili': ['negative', 'small', 'moderate', 'large'],
    'ua_blood': ['negative', 'small', 'moderate', 'large', 'other'],
    'ua_clarity': ['clear', 'not_clear'],
    'ua_color': ['colorless', 'yellow', 'amber', 'orange', 'red'],
    'ua_epi': ['negative', 'small', 'moderate', 'large'],
    'ua_glucose': ['negative', 'small', 'moderate', 'large'],
    'ua_ketones': ['negative', 'small', 'moderate', 'large', 'other'],
    'ua_leuk': ['negative', 'small', 'moderate', 'large', 'other'],
    'ua_nitrite': ['negative', 'positive', 'other'],
    'ua_ph': ['5.0', '5.5', '6.0', '6.5', '7.0', '7.5', '8.0', '8.5', 'other'],
    'ua_protein': ['negative', 'small', 'moderate', 'large'],
    'ua_rbc': ['negative', 'small', 'moderate', 'large', 'other'],
    'ua_wbc': ['negative', 'small', 'moderate', 'large', 'other']
}

for col, order in ordinal_mappings.items():
    encoded_df[col] = pd.Categorical(encoded_df[col], categories=order, ordered=True).codes

# One-Hot Encoding for categorical columns without a natural order
one_hot_cols = ['ethnicity']

# Use pd.get_dummies to one-hot encode the specified columns
encoded_df = pd.get_dummies(encoded_df, columns=one_hot_cols)

encoded_df['Female'] = encoded_df['gender'].apply(lambda x: True if x == 'Female' else False)
encoded_df = encoded_df.drop(columns=['gender'])

encoded_df.head(20)


encoded_df.to_csv('encoded_dataset.csv', index=False)



