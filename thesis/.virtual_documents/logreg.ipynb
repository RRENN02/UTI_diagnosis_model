import pandas as pd
import numpy as np
import optuna
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split, cross_val_score
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler


data = pd.read_csv('encoded_dataset.csv')
data


# Define features and target
X = data.drop(columns=['UCX_abnormal', 'ID', 'PATID'])  # Dropping ID columns and target
y = data['UCX_abnormal']


# Optional: Standardize features if necessary
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


# Define the Optuna objective function for logistic regression
def objective(trial):
    # Suggest the regularization strength 'C' (inverse of regularization strength)
    C = trial.suggest_loguniform('C', 1e-5, 1e2)
    
    # Define the logistic regression model
    model = LogisticRegression(C=C, max_iter=1000, solver='liblinear')
    
    # Perform cross-validation
    score = cross_val_score(model, X_scaled, y, cv=3, scoring='accuracy')
    
    # Return the negative mean score (Optuna minimizes)
    return -score.mean()


# Create a study object for logistic regression
study = optuna.create_study(direction='minimize')  # Minimize the negative accuracy


# Optimize the study
study.optimize(objective, n_trials=50)  # Run the optimization for 50 trials


# Get the best parameters
print(f"Best parameters: {study.best_params}")
print(f"Best score: {-study.best_value}")


# Train the final model using the best parameters
best_params = study.best_params
final_model = LogisticRegression(**best_params, max_iter=1000, solver='liblinear')


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train the model on the training set
final_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = final_model.predict(X_test)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)


# Print the metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)
