import optuna
import pandas as pd
import numpy as np
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
from sklearn.preprocessing import StandardScaler


data = pd.read_csv('encoded_dataset.csv')
data


# Define features and target
X = data.drop(columns=['UCX_abnormal', 'ID', 'PATID'])  # Dropping ID columns and target
y = data['UCX_abnormal']


# Optional: Standardize features if necessary
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


# Encode the labels as TabNet requires numerical labels
y_encoded = LabelEncoder().fit_transform(y)


# Define the Optuna objective function for TabNet
def objective(trial):
    # Suggest hyperparameters for the TabNet model
    n_d = trial.suggest_int('n_d', 8, 64)  # Dimensionality of the decision layer
    n_a = trial.suggest_int('n_a', 8, 64)  # Dimensionality of the attention layer
    n_steps = trial.suggest_int('n_steps', 3, 10)  # Number of steps in the architecture
    gamma = trial.suggest_float('gamma', 1.0, 2.0)  # Relaxation parameter
    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-5, 1e-3, log=True)  # Sparse regularization strength
    n_independent = trial.suggest_int('n_independent', 1, 5)  # Number of independent Gated Linear Units
    n_shared = trial.suggest_int('n_shared', 1, 5)  # Number of shared Gated Linear Units

    # Define the TabNet model
    model = TabNetClassifier(
        n_d=n_d,
        n_a=n_a,
        n_steps=n_steps,
        gamma=gamma,
        lambda_sparse=lambda_sparse,
        n_independent=n_independent,
        n_shared=n_shared,
        verbose=0
    )
    
    # Split the data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)
    
    # Train the model
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric=['accuracy'],
        max_epochs=100,
        patience=10,  # Early stopping
        batch_size=1024,
        virtual_batch_size=128
    )
    
    # Make predictions on the validation set
    y_pred_val = model.predict(X_val)
    
    # Calculate validation accuracy
    accuracy = accuracy_score(y_val, y_pred_val)
    
    # Return the negative accuracy (Optuna minimizes)
    return -accuracy



# Create a study object for TabNet
study = optuna.create_study(direction='minimize')  # Minimize the negative accuracy


# Optimize the study
study.optimize(objective, n_trials=30)  # Run the optimization for 30 trials



# Get the best parameters
print(f"Best parameters: {study.best_params}")
print(f"Best score: {-study.best_value}")


# Train the final model using the best parameters
best_params = study.best_params
final_model = TabNetClassifier(
    n_d=best_params['n_d'],
    n_a=best_params['n_a'],
    n_steps=best_params['n_steps'],
    gamma=best_params['gamma'],
    lambda_sparse=best_params['lambda_sparse'],
    n_independent=best_params['n_independent'],
    n_shared=best_params['n_shared'],
    verbose=0
)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

# Train the model on the training set
final_model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    eval_metric=['accuracy'],
    max_epochs=100,
    patience=10,  # Early stopping
    batch_size=1024,
    virtual_batch_size=128
)

# Make predictions on the test set
y_pred = final_model.predict(X_test)


# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)


# Print the metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)


import shap 

# Create the SHAP explainer
explainer = shap.Explainer(final_model, X_train)

# Generate SHAP values for the test set
shap_values = explainer(X_test)

# Visualize global feature importance
shap.summary_plot(shap_values, X_test)

# Visualize a single prediction
shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0])



